{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/names\\\\Arabic.txt', '../data/names\\\\Chinese.txt', '../data/names\\\\Czech.txt', '../data/names\\\\Dutch.txt', '../data/names\\\\English.txt', '../data/names\\\\French.txt', '../data/names\\\\German.txt', '../data/names\\\\Greek.txt', '../data/names\\\\Irish.txt', '../data/names\\\\Italian.txt', '../data/names\\\\Japanese.txt', '../data/names\\\\Korean.txt', '../data/names\\\\Polish.txt', '../data/names\\\\Portuguese.txt', '../data/names\\\\Russian.txt', '../data/names\\\\Scottish.txt', '../data/names\\\\Spanish.txt', '../data/names\\\\Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "files_path = '../data/names/*.txt'\n",
    "def find_files(path): return(glob.glob(path))\n",
    "\n",
    "print(find_files(files_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "#Turn unicode strings to ASCII\n",
    "def unicode_to_ascii(s):\n",
    "\treturn ''.join(\n",
    "\t\tchar for char in unicodedata.normalize('NFD', s)\n",
    "\t\tif unicodedata.category(char) != 'Mn' and char in all_letters\n",
    "\t)\n",
    "\n",
    "print(unicode_to_ascii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Khoury', 'Nahas', 'Daher', 'Gerges', 'Nazari']\n"
     ]
    }
   ],
   "source": [
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# read a file and split it into lines\n",
    "def read_lines(file_name):\n",
    "\tlines = open(file_name, encoding='utf-8').read().strip().split('\\n')\n",
    "\treturn[unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "for file_name in find_files(files_path):\n",
    "\tcategory = os.path.splitext(os.path.basename(file_name))[0]\n",
    "\tall_categories.append(category)\n",
    "\tlines = read_lines(file_name)\n",
    "\tcategory_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print(category_lines['Arabic'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convert words to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([3, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def letter_index(letter):\n",
    "\treturn all_letters.find(letter)\n",
    "\n",
    "def letter_to_tensor(letter):\n",
    "\ttensor = torch.zeros(1, n_letters)\n",
    "\ttensor[0][letter_index(letter)] = 1\n",
    "\treturn tensor\n",
    "\n",
    "def word_to_tensor(word):\n",
    "\ttensor = torch.zeros(len(word), 1, n_letters)\n",
    "\tfor li, letter in enumerate(word):\n",
    "\t\ttensor[li][0][letter_index(letter)] = 1\n",
    "\treturn tensor\n",
    "\n",
    "print(letter_index('K'))\n",
    "print(letter_to_tensor('a'))\n",
    "print(word_to_tensor('abc').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. RNN Network design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "RNN                                      --\n",
      "├─Linear: 1-1                            7,424\n",
      "├─Linear: 1-2                            16,512\n",
      "├─Linear: 1-3                            2,322\n",
      "├─LogSoftmax: 1-4                        --\n",
      "=================================================================\n",
      "Total params: 26,258\n",
      "Trainable params: 26,258\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "print(summary(rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1447, -0.1512, -0.0462,  0.0378, -0.0272,  0.0865, -0.1072,  0.0457,\n",
      "          0.1263, -0.0115, -0.1232,  0.0299, -0.0021,  0.1349, -0.1821, -0.0454,\n",
      "          0.0132,  0.1349,  0.1013, -0.2199, -0.2411,  0.0691, -0.0732, -0.0198,\n",
      "         -0.0259,  0.0060,  0.0868,  0.0205,  0.0364, -0.0270, -0.1076, -0.1061,\n",
      "          0.2526,  0.0429, -0.0818, -0.0126, -0.1232,  0.0953, -0.0693,  0.0078,\n",
      "         -0.0837, -0.0430,  0.1228,  0.0030, -0.0246, -0.0420,  0.1188, -0.3048,\n",
      "          0.1657,  0.0510, -0.0451,  0.1143, -0.1227, -0.0630,  0.0284, -0.1008,\n",
      "          0.0566, -0.1749,  0.0127, -0.0451,  0.0439, -0.0319, -0.1743, -0.0397,\n",
      "          0.0778, -0.1822,  0.0654, -0.0158, -0.0979, -0.0595, -0.0740, -0.2435,\n",
      "          0.0022, -0.0104,  0.0071,  0.1444,  0.1011,  0.0457, -0.0607, -0.0658,\n",
      "         -0.0062, -0.0786,  0.0271,  0.1777, -0.0894,  0.1612,  0.0932, -0.0561,\n",
      "         -0.1343,  0.2906,  0.2672,  0.0531,  0.0243,  0.2434,  0.0251,  0.0076,\n",
      "         -0.2629,  0.2194,  0.1800,  0.0038,  0.1475,  0.0633, -0.1117,  0.2223,\n",
      "         -0.1211,  0.1545, -0.0961, -0.1735, -0.0637,  0.0969, -0.1207, -0.1203,\n",
      "          0.1208, -0.2636, -0.0804,  0.1697,  0.1095,  0.0779, -0.1954,  0.1016,\n",
      "          0.0662, -0.0331,  0.1297,  0.0342, -0.0852,  0.0403, -0.0382, -0.0127]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = word_to_tensor('Attah')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
